{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv,sys\n",
    "import math,random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "    #An point in n dimensional space\n",
    "    def __init__(self, coords,label):\n",
    "    #coords - A list of values, one per dimension\n",
    "        self.coords = coords\n",
    "        self.label = label\n",
    "        self.n = len(coords)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    #A set of points and their centroid\n",
    "\n",
    "    def __init__(self, points):\n",
    "    #points - A list of point objects\n",
    "\n",
    "        if len(points) == 0: \n",
    "            raise Exception(\"ILLEGAL: empty cluster\")\n",
    "        # The points that belong to this cluster\n",
    "        self.points = points\n",
    "\n",
    "        # The dimensionality of the points in this cluster\n",
    "        self.n = points[0].n\n",
    "        self.length = 1\n",
    "    \n",
    "        # Assert that all points are of the same dimensionality\n",
    "        for p in points:\n",
    "            if p.n != self.n: raise Exception(\"ILLEGAL: wrong dimensions\")\n",
    "    \n",
    "        # Set up the initial centroid (this is usually based off one point)\n",
    "        self.centroid = self.calculateCentroid()\n",
    "\n",
    "    def __repr__(self):\n",
    "    #String representation of this object\n",
    "        return str(self.points)\n",
    "\n",
    "    def update(self, points):\n",
    "    #Returns the distance between the previous centroid and the new after\n",
    "    #recalculating and storing the new centroid.\n",
    "        old_centroid = self.centroid\n",
    "        self.points = points\n",
    "        self.centroid = self.calculateCentroid()\n",
    "        shift = getDistance(old_centroid, self.centroid) \n",
    "        return shift\n",
    "\n",
    "    def calculateCentroid(self):\n",
    "    #Finds a virtual center point for a group of n-dimensional points\n",
    "        numPoints = len(self.points)\n",
    "        # Get a list of all coordinates in this cluster\n",
    "        coords = [p.coords for p in self.points]\n",
    "        # Reformat that so all x's are together, all y'z etc.\n",
    "        unzipped = zip(*coords)\n",
    "        # Calculate the mean for each dimension\n",
    "        centroid_coords = [math.fsum(dList)/numPoints for dList in unzipped]\n",
    "\n",
    "        return Point(centroid_coords,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistance(a, b):\n",
    "\n",
    "#Euclidean distance between two n-dimensional points.\n",
    "#Note: This can be very slow and does not scale well\n",
    "    #if a.n != b.n:\n",
    "    #    raise Exception(\"ILLEGAL: non comparable points\")\n",
    "\n",
    "    ret = reduce(lambda x,y: x + pow((a.coords[y]-b.coords[y]), 2),range(a.n),0.0)\n",
    "    return math.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(points, k, cutoff):\n",
    "\n",
    "    # Pick out k random points to use as our initial centroids\n",
    "    initial = random.sample(points, k)\n",
    "\n",
    "    # Create k clusters using those centroids\n",
    "    clusters = [Cluster([p]) for p in initial]\n",
    "\n",
    "    # Loop through the dataset until the clusters stabilize\n",
    "    loopCounter = 0\n",
    "    while True:\n",
    "        # Create a list of lists to hold the points in each cluster\n",
    "        lists = [ [] for c in clusters]\n",
    "        clusterCount = len(clusters)\n",
    "\n",
    "        # Start counting loops\n",
    "        loopCounter += 1\n",
    "        # For every point in the dataset ...\n",
    "        for p in points:\n",
    "            # Get the distance between that point and the centroid of the first\n",
    "            # cluster.\n",
    "            smallest_distance = getDistance(p, clusters[0].centroid)\n",
    "\n",
    "            # Set the cluster this point belongs to\n",
    "            clusterIndex = 0\n",
    "\n",
    "            # For the remainder of the clusters ...\n",
    "            for i in range(clusterCount - 1):\n",
    "                # calculate the distance of that point to each other cluster's\n",
    "                # centroid.\n",
    "                distance = getDistance(p, clusters[i+1].centroid)\n",
    "                # If it's closer to that cluster's centroid update what we\n",
    "                # think the smallest distance is, and set the point to belong\n",
    "                # to that cluster\n",
    "                if distance < smallest_distance:\n",
    "                    smallest_distance = distance\n",
    "                    clusterIndex = i+1\n",
    "            lists[clusterIndex].append(p)\n",
    "\n",
    "        # Set our biggest_shift to zero for this iteration\n",
    "        biggest_shift = 0.0\n",
    "\n",
    "        # As many times as there are clusters ...\n",
    "        for i in range(clusterCount):\n",
    "            # Calculate how far the centroid moved in this iteration\n",
    "            shift = clusters[i].update(lists[i])\n",
    "            clusters[i].length = len(lists[i])\n",
    "            # Keep track of the largest move from all cluster centroid updates\n",
    "            biggest_shift = max(biggest_shift, shift)\n",
    "\n",
    "        # If the centroids have stopped moving much, say we're done!\n",
    "        if biggest_shift < cutoff:\n",
    "            #print \"Converged after %s iterations\" % loopCounter\n",
    "            break\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = pd.read_csv(\"arcene_train.data\",delimiter = ' ')\n",
    "    data = np.array(data)\n",
    "    #np.any(np.isnan(data))\n",
    "    data = list(data)\n",
    "    #print data[0]\n",
    "    temp = []\n",
    "    for row in data:\n",
    "        temp.append([int(elements) for elements in row[:10000]])\n",
    "    data = temp\n",
    "    #print data[0]\n",
    "    k = 50\n",
    "    temp = []\n",
    "    data = np.array(data)\n",
    "    kpca = KernelPCA(k,kernel='poly',degree=3)\n",
    "    data_x = kpca.fit_transform(data)\n",
    "    data_x = list(data_x)\n",
    "    for p in data_x:\n",
    "        temp.append(list(p))\n",
    "    data_x = temp\n",
    "    #print data_x\n",
    "    #print len(data_x[0])\n",
    "    labels = pd.read_csv(\"arcene_train.labels\", delimiter = ' ')\n",
    "    labels = np.array(labels)\n",
    "    labels = list(labels)\n",
    "    temp = []\n",
    "    for row in labels:\n",
    "        temp.append(int(row))\n",
    "    labels = temp\n",
    "    points = []\n",
    "    for i in range(len(data_x)):\n",
    "        points.append(Point(data_x[i],labels[i]))\n",
    "    num_clusters = 2\n",
    "    opt_cutoff = 0.5\n",
    "    clusters = kmeans(points,num_clusters,opt_cutoff)\n",
    "    #print len(clusters)\n",
    "    accuracy = 0.0\n",
    "    count_class = dict()\n",
    "    for i in range(len(clusters)):\n",
    "        #print (clusters[i])\n",
    "        #print clusters[i].length\n",
    "        for p in clusters[i].points:\n",
    "            #clusters[i] = list(clusters[i])\n",
    "            if p.label in count_class.keys():\n",
    "                count_class[p.label]+=1\n",
    "            else:\n",
    "                count_class[p.label]=1\n",
    "        max_count = 0\n",
    "        for key in count_class:\n",
    "            if count_class[key]> max_count:\n",
    "                max_count = count_class[key]\n",
    "        accuracy += max_count\n",
    "        count_class.clear()\n",
    "    accuracy = accuracy/len(data)\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606060606061\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
