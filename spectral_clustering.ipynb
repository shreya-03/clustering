{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv,sys\n",
    "import math,random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Point:\n",
    "    #An point in n dimensional space\n",
    "    def __init__(self, coords,label):\n",
    "    #coords - A list of values, one per dimension\n",
    "        self.coords = coords\n",
    "        self.label = label\n",
    "        self.n = len(coords)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    #A set of points and their centroid\n",
    "\n",
    "    def __init__(self, points):\n",
    "    #points - A list of point objects\n",
    "\n",
    "        if len(points) == 0: \n",
    "            raise Exception(\"ILLEGAL: empty cluster\")\n",
    "        # The points that belong to this cluster\n",
    "        self.points = points\n",
    "\n",
    "        # The dimensionality of the points in this cluster\n",
    "        self.n = points[0].n\n",
    "        self.length = 1\n",
    "    \n",
    "        # Assert that all points are of the same dimensionality\n",
    "        for p in points:\n",
    "            if p.n != self.n: raise Exception(\"ILLEGAL: wrong dimensions\")\n",
    "    \n",
    "        # Set up the initial centroid (this is usually based off one point)\n",
    "        self.centroid = self.calculateCentroid()\n",
    "\n",
    "    def __repr__(self):\n",
    "    #String representation of this object\n",
    "        return str(self.points)\n",
    "\n",
    "    def update(self, points):\n",
    "    #Returns the distance between the previous centroid and the new after\n",
    "    #recalculating and storing the new centroid.\n",
    "        old_centroid = self.centroid\n",
    "        self.points = points\n",
    "        self.centroid = self.calculateCentroid()\n",
    "        shift = getDistance(old_centroid.coords, self.centroid.coords) \n",
    "        return shift\n",
    "\n",
    "    def calculateCentroid(self):\n",
    "    #Finds a virtual center point for a group of n-dimensional points\n",
    "        numPoints = len(self.points)\n",
    "        # Get a list of all coordinates in this cluster\n",
    "        coords = [p.coords for p in self.points]\n",
    "        # Reformat that so all x's are together, all y'z etc.\n",
    "        unzipped = zip(*coords)\n",
    "        # Calculate the mean for each dimension\n",
    "        centroid_coords = [math.fsum(dList)/numPoints for dList in unzipped]\n",
    "\n",
    "        return Point(centroid_coords,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistance(a, b):\n",
    "\n",
    "#Euclidean distance between two n-dimensional points.\n",
    "#Note: This can be very slow and does not scale well\n",
    "    #if a.n != b.n:\n",
    "    #    raise Exception(\"ILLEGAL: non comparable points\")\n",
    "\n",
    "    ret = reduce(lambda x,y: x + pow((a[y]-b[y]), 2),range(len(a)),0.0)\n",
    "    return math.sqrt(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(points, k, cutoff):\n",
    "\n",
    "    # Pick out k random points to use as our initial centroids\n",
    "    initial = random.sample(points, k)\n",
    "\n",
    "    # Create k clusters using those centroids\n",
    "    clusters = [Cluster([p]) for p in initial]\n",
    "\n",
    "    # Loop through the dataset until the clusters stabilize\n",
    "    loopCounter = 0\n",
    "    while True:\n",
    "        # Create a list of lists to hold the points in each cluster\n",
    "        lists = [ [] for c in clusters]\n",
    "        clusterCount = len(clusters)\n",
    "\n",
    "        # Start counting loops\n",
    "        loopCounter += 1\n",
    "        # For every point in the dataset ...\n",
    "        for p in points:\n",
    "            # Get the distance between that point and the centroid of the first\n",
    "            # cluster.\n",
    "            smallest_distance = getDistance(p.coords, clusters[0].centroid.coords)\n",
    "\n",
    "            # Set the cluster this point belongs to\n",
    "            clusterIndex = 0\n",
    "\n",
    "            # For the remainder of the clusters ...\n",
    "            for i in range(clusterCount - 1):\n",
    "                # calculate the distance of that point to each other cluster's\n",
    "                # centroid.\n",
    "                distance = getDistance(p.coords, clusters[i+1].centroid.coords)\n",
    "                # If it's closer to that cluster's centroid update what we\n",
    "                # think the smallest distance is, and set the point to belong\n",
    "                # to that cluster\n",
    "                if distance < smallest_distance:\n",
    "                    smallest_distance = distance\n",
    "                    clusterIndex = i+1\n",
    "            lists[clusterIndex].append(p)\n",
    "\n",
    "        # Set our biggest_shift to zero for this iteration\n",
    "        biggest_shift = 0.0\n",
    "\n",
    "        # As many times as there are clusters ...\n",
    "        for i in range(clusterCount):\n",
    "            # Calculate how far the centroid moved in this iteration\n",
    "            shift = clusters[i].update(lists[i])\n",
    "            clusters[i].length = len(lists[i])\n",
    "            # Keep track of the largest move from all cluster centroid updates\n",
    "            biggest_shift = max(biggest_shift, shift)\n",
    "\n",
    "        # If the centroids have stopped moving much, say we're done!\n",
    "        if biggest_shift < cutoff:\n",
    "            #print \"Converged after %s iterations\" % loopCounter\n",
    "            break\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_matrix(points):\n",
    "    S = []\n",
    "    for i in range(0, len(points)):\n",
    "        row = []\n",
    "        for j in range(0, len(points)):\n",
    "                # scaled pairwise comparison\n",
    "            if i == j:\n",
    "                row.append(0)\n",
    "            else:\n",
    "                row.append(getDistance(points[i],points[j]))\n",
    "        S.append(row)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjacency_matrix(points,knn,S):\n",
    "    A = []\n",
    "    if knn < len(points):\n",
    "        for i in range(0, len(S)):\n",
    "            A.append([])\n",
    "            row = S[i][:]\n",
    "            row.sort()\n",
    "            row = row[:knn]\n",
    "            for j in range(0, len(S[i])):\n",
    "                if S[i][j] in row:\n",
    "                    A[i].append(S[i][j])\n",
    "                else:\n",
    "                    A[i].append(0)\n",
    "    else:\n",
    "        A = S\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diag_degree_matrix(S,A):\n",
    "    D = []\n",
    "    for j in range(0, len(S)):\n",
    "        D.append([])\n",
    "        dj = 0\n",
    "        index = 0\n",
    "        for i in range(0, len(S[j])):\n",
    "            D[j].append(0)\n",
    "            if i == j:\n",
    "                index = i\n",
    "            dj += A[j][i]\n",
    "        D[j][index] = dj\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = pd.read_csv(\"arcene_train.data\",delimiter = ' ')\n",
    "    data = np.array(data)\n",
    "    #np.any(np.isnan(data))\n",
    "    data = list(data)\n",
    "    #print data[0]\n",
    "    temp = []\n",
    "    for row in data:\n",
    "        temp.append([int(elements) for elements in row[:10000]])\n",
    "    data = temp\n",
    "    labels = pd.read_csv(\"arcene_train.labels\", delimiter = ' ')\n",
    "    labels = np.array(labels)\n",
    "    labels = list(labels)\n",
    "    temp = []\n",
    "    for row in labels:\n",
    "        temp.append(int(row))\n",
    "    labels = temp\n",
    "    S = similarity_matrix(data)\n",
    "    #print len(S[0])\n",
    "    A = adjacency_matrix(data,8,S)\n",
    "    #print A\n",
    "    D = diag_degree_matrix(S,A)\n",
    "    #print D\n",
    "    temp = []\n",
    "    for p in D:\n",
    "        temp.append([np.array(element) for element in p])\n",
    "    D = np.array(temp)\n",
    "    sqrt_D = linalg.sqrtm(D)\n",
    "    inv_D = linalg.inv(sqrt_D)\n",
    "    invsqrt_D = linalg.sqrtm(inv_D)\n",
    "    L = np.dot(np.dot(invsqrt_D,A),sqrt_D)\n",
    "    #print len(L)\n",
    "    #print len(L[0])\n",
    "    k = 5\n",
    "    eig_vals, eig_vecs = linalg.eig(L)\n",
    "    eig_pairs = [((eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "    # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "    eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True)\n",
    "    vec = np.array([ eig_pairs[i][1] for i in range(k)])\n",
    "    vec = np.transpose(vec)\n",
    "    vec = list(vec)\n",
    "    temp = []\n",
    "    for p in vec:\n",
    "        temp.append([float(elements) for elements in p])\n",
    "    vec = temp\n",
    "    print type(vec[i])\n",
    "    points = []\n",
    "    for i in range(len(vec)):\n",
    "        points.append(Point(vec[i],labels[i]))\n",
    "    num_clusters = 2\n",
    "    opt_cutoff = 0.5\n",
    "    clusters = kmeans(points,num_clusters,opt_cutoff)\n",
    "    accuracy = 0.0\n",
    "    count_class = dict()\n",
    "    for i in range(len(clusters)):\n",
    "        #print (clusters[i])\n",
    "        #print clusters[i].length\n",
    "        for p in clusters[i].points:\n",
    "            #clusters[i] = list(clusters[i])\n",
    "            if p.label in count_class.keys():\n",
    "                count_class[p.label]+=1\n",
    "            else:\n",
    "                count_class[p.label]=1\n",
    "        max_count = 0\n",
    "        for key in count_class:\n",
    "            if count_class[key]> max_count:\n",
    "                max_count = count_class[key]\n",
    "        accuracy += max_count\n",
    "        count_class.clear()\n",
    "    accuracy = accuracy/len(data)\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "0.575757575758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:44: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
